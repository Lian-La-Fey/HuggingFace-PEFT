{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# Quicktour\n","\n","PEFT, önceden eğitilmiş büyük modellere ince ayar yapmak için parametre etkin yöntemler sunar. Geleneksel paradigma, her bir alt görev için bir modelin tüm parametrelerine ince ayar yapmaktır, ancak günümüzde modellerdeki muazzam parametre sayısı nedeniyle bu son derece maliyetli ve pratik değildir. Bunun yerine, daha az sayıda hızlı parametreyi eğitmek veya eğitilebilir parametrelerin sayısını azaltmak için düşük sıralı adaptasyon (LoRA) gibi bir yeniden parametrizasyon yöntemi kullanmak daha verimlidir.\n","\n","Bu hızlı tur size PEFT'in temel özelliklerini ve tüketici cihazlarında genellikle erişilemeyen büyük modelleri nasıl eğitebileceğinizi veya bu modeller üzerinde nasıl çıkarım yapabileceğinizi gösterecektir."]},{"cell_type":"markdown","metadata":{},"source":["## Train\n","\n","Her PEFT yöntemi, bir **PeftModel** oluşturmak için tüm önemli parametreleri saklayan bir `PeftConfig` sınıfı tarafından tanımlanır. Örneğin, LoRA ile eğitmek için bir **LoraConfig** sınıfı yükleyip oluşturun ve aşağıdaki parametreleri belirtin:\n","\n","- `task_type`: eğitilecek görev (bu durumda diziden diziye dil modelleme) \n","- `inference_mode`: modeli çıkarım için kullanıp kullanmayacağınız \n","- `r`: düşük sıralı matrislerin boyutu \n","- `lora_alpha`: düşük sıralı matrisler için ölçeklendirme faktörü \n","- `lora_dropout`: LoRA katmanlarının bırakma olasılığı"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-10T18:32:43.485848Z","iopub.status.busy":"2024-08-10T18:32:43.484976Z","iopub.status.idle":"2024-08-10T18:32:57.159741Z","shell.execute_reply":"2024-08-10T18:32:57.158469Z","shell.execute_reply.started":"2024-08-10T18:32:43.485815Z"},"trusted":true},"outputs":[],"source":["!pip install -q peft"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-10T18:32:57.162109Z","iopub.status.busy":"2024-08-10T18:32:57.161797Z","iopub.status.idle":"2024-08-10T18:33:02.294179Z","shell.execute_reply":"2024-08-10T18:33:02.293423Z","shell.execute_reply.started":"2024-08-10T18:32:57.162080Z"},"trusted":true},"outputs":[],"source":["from peft import LoraConfig, TaskType\n","\n","peft_config = LoraConfig(\n","    task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, \n","    r=8, lora_alpha=32, lora_dropout=0.1\n",")"]},{"cell_type":"markdown","metadata":{},"source":["LoraConfig kurulduktan sonra **get_peft_model()** fonksiyonu ile bir **PeftModel** oluşturun. Transformers kütüphanesinden yükleyebileceğiniz bir temel modeli ve LoRA ile eğitim için bir modelin nasıl yapılandırılacağına ilişkin parametreleri içeren LoraConfig'i alır.\n","\n","İnce ayar yapmak istediğiniz temel modeli yükleyin."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-10T18:33:02.295657Z","iopub.status.busy":"2024-08-10T18:33:02.295215Z","iopub.status.idle":"2024-08-10T18:33:27.791038Z","shell.execute_reply":"2024-08-10T18:33:27.790212Z","shell.execute_reply.started":"2024-08-10T18:33:02.295630Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb1c0fa3cbd84ccfbf5a10d5ac448175","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/800 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"020a6df16c984e95a1a5abd1ab79d176","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/mt0-large\")"]},{"cell_type":"markdown","metadata":{},"source":["Bir **PeftModel** oluşturmak için temel modeli ve **peft_config**'i **get_peft_model()** işleviyle sarın. Modelinizdeki eğitilebilir parametrelerin sayısı hakkında bir fikir edinmek için **print_trainable_parameters** metodunu kullanın"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-10T18:33:27.793522Z","iopub.status.busy":"2024-08-10T18:33:27.793228Z","iopub.status.idle":"2024-08-10T18:33:28.128996Z","shell.execute_reply":"2024-08-10T18:33:28.127999Z","shell.execute_reply.started":"2024-08-10T18:33:27.793495Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 2,359,296 || all params: 1,231,940,608 || trainable%: 0.1915\n"]}],"source":["from peft import get_peft_model\n","\n","model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"markdown","metadata":{},"source":["bigscience/mt0-large'ın 1.2B parametresinden sadece %0.19'unu eğitiyorsunuz!\n","\n","Artık modeli Transformers Trainer, Accelerate veya herhangi bir özel PyTorch eğitim döngüsü ile eğitebilirsiniz.\n","\n","Örneğin, **Trainer** sınıfı ile eğitmek için, bazı eğitim hiper parametreleri ile bir **TrainingArguments** sınıfı oluşturun."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-10T18:33:28.130459Z","iopub.status.busy":"2024-08-10T18:33:28.130171Z","iopub.status.idle":"2024-08-10T18:33:44.825773Z","shell.execute_reply":"2024-08-10T18:33:44.824975Z","shell.execute_reply.started":"2024-08-10T18:33:28.130433Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","2024-08-10 18:33:32.605158: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-10 18:33:32.605293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-10 18:33:32.725379: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"Leotrim/bigscience/mt0-large-lora\",\n","    learning_rate=1e-3,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["```\n","from trasnformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Save model\n","\n","Modelinizin eğitimi tamamlandıktan sonra save_pretrained fonksiyonunu kullanarak modelinizi bir dizine kaydedebilirsiniz.\n","\n","`model.save_pretrained(\"output_dir\")`\n","\n","Ayrıca push_to_hub fonksiyonunu kullanarak modelinizi Hub'a kaydedebilirsiniz (önce Hugging Face hesabınıza giriş yaptığınızdan emin olun).\n","\n","```\n","from huggingface_hub import notebook_login\n","\n","notebook_login()\n","model.push_to_hub(\"your-name/bigscience/mt0-large-lora\")\n","```\n","\n","Her iki yöntem de yalnızca eğitilen ekstra PEFT ağırlıklarını kaydeder, bu da depolamanın, aktarmanın ve yüklemenin süper verimli olduğu anlamına gelir. Örneğin, LoRA ile eğitilen bu facebook/opt-350m modeli yalnızca iki dosya içerir: adapter_config.json ve adapter_model.safetensors. adapter_model.safetensors dosyası sadece 6,3 MB!\n","\n","![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/PEFT-hub-screenshot.png)"]},{"cell_type":"markdown","metadata":{},"source":["## Inference\n","\n","**AutoPeftModel** sınıfı ve **from_pretrained** yöntemi ile çıkarım için herhangi bir PEFT eğitimli modeli kolayca yükleyin:"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-10T18:33:44.827629Z","iopub.status.busy":"2024-08-10T18:33:44.826949Z","iopub.status.idle":"2024-08-10T18:33:51.905404Z","shell.execute_reply":"2024-08-10T18:33:51.904617Z","shell.execute_reply.started":"2024-08-10T18:33:44.827594Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de2d926c1e2043608931013b118e1f02","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/416 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4eb906ddae1400e806ebd439cab45cf","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4dff6e0d44304253ab04bf1b78ac2331","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3af2b7596c2149c2883f4df0dd4fe691","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f37bf92ce6514a209c57a9d097e21bba","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/6.30M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"742126eb5ebf48d5970c5a2cc3e26516","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84597d0033534e2aab7047d78beda2d1","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b88c8782ba24dd3aa2ae57c2ba1e841","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf61f85d0d8e46ccba7be447287c8e1e","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","\n","from transformers import AutoTokenizer\n","from peft import AutoPeftModelForCausalLM\n","\n","model = AutoPeftModelForCausalLM.from_pretrained(\"ybelkada/opt-350m-lora\")\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-10T18:33:51.906794Z","iopub.status.busy":"2024-08-10T18:33:51.906474Z","iopub.status.idle":"2024-08-10T18:33:54.894746Z","shell.execute_reply":"2024-08-10T18:33:54.893545Z","shell.execute_reply.started":"2024-08-10T18:33:51.906766Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Preheat the oven to 350 degrees and place the cookie dough in the center of the oven.\n","\n","In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon.\n","\n","In a separate bowl, combine the egg yolks, sugar, and vanilla.\n","\n","\n"]},{"data":{"text/plain":["'Preheat the oven to 350 degrees and place the cookie dough in the center of the oven. In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon. In a separate bowl, combine the egg yolks, sugar, and vanilla.'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model = model.to(\"cuda\")\n","model.eval()\n","inputs = tokenizer(\"Preheat the oven to 350 degrees and place the cookie dough\", return_tensors=\"pt\")\n","\n","outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=50)\n","print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])"]},{"cell_type":"markdown","metadata":{},"source":["Otomatik konuşma tanıma gibi AutoPeftModelFor sınıfı ile açıkça desteklenmeyen diğer görevler için, görev için bir model yüklemek üzere temel AutoPeftModel sınıfını kullanmaya devam edebilirsiniz."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-10T18:36:15.178789Z","iopub.status.busy":"2024-08-10T18:36:15.177924Z","iopub.status.idle":"2024-08-10T18:36:15.182638Z","shell.execute_reply":"2024-08-10T18:36:15.181653Z","shell.execute_reply.started":"2024-08-10T18:36:15.178754Z"},"trusted":true},"outputs":[],"source":["# from peft import AutoPeftModel\n","\n","# model = AutoPeftModel.from_pretrained(\"smangrul/openai-whisper-large-v2-LORA-colab\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
